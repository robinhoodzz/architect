# Redis

### 常识

* 可以访问redis.cn上面有大量知识和案例

* 磁盘的维度
  1. 寻址的速度: ms毫秒级别的
  2. 带宽: 单位时间有多少个字节流动, GB/MB 级别
* 内存
  * 寻址的速度: ns 纳秒 (秒>毫秒>微秒>纳秒)
    * 硬盘在寻址上比内存慢了10万倍
  * 带宽: 很大
* I/O buffer 成本问题
  * 磁盘有磁道和扇区
    * 一扇区 512Byte字节
    * 如果一个区域足够小, 带来的问题是成本变大->索引
    * 格式化磁盘时有4K对齐, 真正使用硬件时并不是512B为读写量
    * 操作系统, 无论读取多少都是最少4K, 从磁盘上拿
  * 随着文件变大, 读取速度变慢
    * 硬盘成为瓶颈, 也就是I/O成为瓶颈
* 数据库的出现
  * data page 概念
    * 大小为4K,  与操作系统一次IO相同, 放一行一行的数据, 
    * 相当于数据块, 并由软件统一管理, 使得其变得更线性, 而不是散落在磁盘各处
      * 如果数据库定义小了, 则亏得慌, 如定义1k, 但每次IO是4K, 有3k没有发挥作用
      * 可以往大了调整
      * 个人理解: Hadoop的数据块概念就可以很大
  * 索引
    * 也是基于4K的数据块
    * 记录并指向data page的地址
    * 存储于硬盘
  * 关系型数据建表: 必须给出schema
    * 类型: 字节宽度
    * 存储: 倾向于行级别的存储, 即使一行除了主键其他字段无数据, 也会给这些字段开辟空间
      * 站位的好处: 为将来增删改提供扩展性, 降低成本
  * 使用索引需要内存中准备一个B+ Tree
    * 所有叶子节点为硬盘上的索引
    * 树干(非叶子节点) 存储于内存之中
  * 命中缓存的流程
    * where条件命中内存中的B+树的节点
    * 也就是命中磁盘中索引块
    * 数据库加载磁盘索引块到内存, 解析得出数据块地址
    * 通过数据块地址将数据块内容加载到内存, 并返回给用户
    * 最终目的减少IO的次数
  * 问题: 如果数据库的表数据量很大, 性能下降, 查询效率会变低
    * 如果表有索引, 增删改变慢
      * 原因, 修改完数据, 还会修改索引, 会调整索引的位置
    * 查询速度
      1. 数据量很大前提下(假设达到物理极限), 1个或者少量查询, 且命中索引的情况下, 依然很快
      2. 并发或复杂SQL到达, 要获取多个data page, 会受硬盘带宽影响速度
    * 解决方案
      1. 使用昂贵的基于内存的关系型数据库
      2. 使用缓存做为中间件
  * 数据在磁盘和内存体积不一样, 因为磁盘中没有对象概念, 引用需要冗余数据
    * 将2T磁盘数据, 转换成内存的数据结构, 要<2T
    * 但是基于内存的关系型数据库很贵, 贵到买不起
* 问题: 数据库数据增长很大很快, 又不可能使用基于内存的关系型数据库, 如何操作?
  * 折中方案: 缓存, 如memcached, redis
* 2个基础设施
  1. 冯诺依曼体系的硬件
  2. 以太网, TCP/IP网络(潜台词: 不稳定)

* **技术选型**&**技术对比**能力
  * [数据库引擎网](https://db-engines.com/en/)    包括了关系型,内存kv型,文档型等等
  * 基于此网站来做数据库的选型

* memcached VS redis

  * 第一反应, memcached即使没有复杂数据类型, 也可以用json表示
    * 世界上有3种数据表示:
      * k = a
      * k = [1,2,3]
      * k = { x = y },  k = [{}, {}]

  * 数据结构
    * memcached: 他的value没有类型的概念
    * redis: 他的value有类型概念, 如string, list等等
    * 这不是重点, 因为可以用json代替
    * 但是, 如果client要从缓存中读取value中的一个元素, 成本就不一样了
      * memcached: 返回所有value到client, 涉及到server,网卡,IO,解码json
      * redis: 类型不是很重要, 重要的是redis的server对每种类型都有自己的方法
      * 这样就规避的了上面的问题, 使用**命令**来代替**编码的实现**, 也实现了解耦
      * **计算向数据移动**

### 源码安装redis

* 安装过程
  1. yum install wget
  2. cd ~  &&  mkdir soft  &&   cd soft
  3. wget redis的下载地址
  4. tar xf redisXX.tar.gz # 这里没有v也是为了规避IO
  5. cd redis-src
  6. 看README.md
  7. make
  8. yum install gcc
  9. make distclean # 因为之间make过, 所以再次make时删除之前make过的内容
  10. make
  11. cd src # 查看, 此时生成了可执行程序
  12. cd.. #出来
  13. make install PREFIX=/opt/mashibing/redis
  14. vi /etc/profile
  15. export REDIS_HOME=/opt/mashibing/redis5
  16. export PATH=$PATH:$REDIS_HOME/bin
  17. source /etc/profile
  18. cd utils
  19. ./install_server.sh # 可执行一次或多次

* 知识点

  * 一个Linux操作系统(不论是物理机还是虚拟机) 可以有多个redis实例(进程), 通过端口号区分
  * 可执行程序只有一份, 但是内存中未来的多个实例, 需要各自的配置文件和持久化目录等资源
  * service redis_6379 start|stop|status  >  linux  /etc/init.d/redis_6379这个脚本

  

### redis特性

* 单进程, 单线程, 单实例, 一秒能hold住很多并发的请求, 那么他是如何变得很快的?
  * 不严谨, 只是针对处理客户端请求时, 是单进程单线程单实例, 后台有备份的线程, 这个是不与客户端交互的
  * 客户端连接, 先到达内核, tcp握手
  * redis和内核之间使用的是 epoll, 非阻塞多路复用技术, 也是内核提供的一种系统调用
  * redis可以通过epoll系统调用, 来遍历不同客户端连接, 谁有数据就处理谁
  * 因为单进程, 所有数据到达并被redis处理是"有顺序的", 后面的共享空间的链表
    * 顺序性特指: 每个连接内的命令的顺序处理的
    * 若, 2个socket对K1进行操作, 很难判定谁先后, epoll先轮到谁了说不准, 所以没法判定顺序, 也就socket1和socket2是都有可能先执行
* epoll
  * BIO时期
    * 当内核下客户端client连接过来, fd 8, fd 9
    * 操作系统提供一种读操作, read命令,  现在有线程/进程read fd8, 和另一线程/进程read fd9
    * 此时socket在这个时期是阻塞的, 也就是read命令阻塞不能返回, 等待client 对fd 8做写入操作
    * 如果现在, fd 9有数据写入, CPU时间片上只能有一个线程处理, 如正在处理fd8的read, 此时间片内还轮不到fd 9处理
    * 这样会导致, 当client增多时, 需要抛出更多的线程, client没有写入数据的时候, 很多线程会阻塞
    * CPU并没有处理真正到达的数据, 资源浪费, 且切换线程是有成本的
  * NIO时期(同步非阻塞时期), 为了提高硬件利用率, 内核发生变化
    * socket fd可以是 nonblock, 通过查询 man read 得出, read 命令有 nonblock选项
    * 此时不阻塞了, CPU可以只跑一个进程, 这个线程里写一个死循环
    * 调用完 read fd 8, 就调用read fd 9
    * 如果fd8没有数据, fd9有数据, 跳过fd8, 处理fd9
    * 这个轮询发生在用户空间(用户态)
    * 同步非阻塞体现在, 调用read方法后可以继续往下走不阻塞, 读fd的数据还是这个唯一的线程来做, 这叫同步
    * 问题: 如果有1000个fd, 代表**用户进程**轮询调用1000次**内核**, 成本很大
      * 也就是用户态和内核态切换, CPU保护现场恢复现场等资源消耗, 成本消耗
      * 想减少系统调用, 用户自己无法实现, 需要内核向前发展
  * select 多路复用的NIO
    * 把用户态的轮询放到了内核里, 内核里多了一个系统调用: select
    * 用户态调用select传入1000个fd, 内核监控这些fd, 内核等待直到有一个或多个I/O操作处于ready状态后返回, 参考: man select
    * 用户态再拿着返回的文件描述符, 再去调用read命令
    * 相当于还是调用wait , 但是不会调用没有ready, 没有数据写入的fd
    * 与上一个时期相比, 系统调用更精准了
    * 还是有问题: 每次要传入很多个fd进去, 返回后再去调用read, 是否还能再优化?
      * 抽象成: 用户态和内核态来回拷贝数据, 能否零拷贝
      * 决策环节时, 文件描述符fd成为累赘了
  * epoll 伪AIO
    * mmap命令, map or unmap files or devices into memory
    * 内核有内核的内存地址空间, 应用进程有应用进程内存地址空间, 都是虚拟地址空间, 物理内存上就是2个不同的区域而已, 内核的区域进程是不能直接访问的, 要通过API传参访问, 也就是拷贝来拷贝去
    * 索性弄出一个内核态和用户态都可以访问的空间, 称之为共享空间
    * 共享空间是通过内核的mmap系统调用实现的
    * 有了共享空间, 用户态就不用在自己的空间里写fd了, 要不然还得再拷贝一次到共享空间
    * 共享空间是用户态内存空间的一部分, 也是内核态内存空间的一部分, 各自无需再单独维护fd
    * 空间中存放了 红黑树和链表 数据结构
      * 进程里(用户态)每多了一个fd, 就放到共享空间里的红黑树
      * 内核获取fd, 通过所有的IO/中断, 把数据达到的(ready)放到链表里
      * 当链表里有数据了, 用户态通过读取链表读取到fd, 再调用read读取数据
    * 零拷贝, sendfile
      * 现在有内核, 网卡, 文件, 应用程序
      * 文件fd3 -> 内核buffer -> read(fd3) -> 应用程序 -> write(fd4) -> 内核buffer -> 网卡请求
      * 有了sendfile之后
      * 文件fd3 -> 内核buffer -> read(fd3) -> 应用程序 -> sendfile(fd4) -> 网卡请求
    * epoll是一个大的概念, 其中有3个系统调用
      * epoll_create
        * 调用create后, 返回epoll的fd, epoll_fd
        * 未来有一个连接进来了, 就写给epoll_fd, epoll会使用共享空间mmap, 连接注册到共享空间内的红黑树, 增删改的操纵是内核完成的, 查询是用户态和内核态都可以操作的
      * epoll_ctl
        * 用户态会调用 ctl add/del sfd(socket的fd) 和 wait命令
        * 事件驱动, 内核完成那个连接fd为ready, 并写到链表里去, 维护数据是可写还是可读
        * 维护完成后, wait解除阻塞, 可以获取链表中的数据, 因为是共享空间, 所以到用户态没有数据拷贝
        * 但是此时还要单独调用 read/write命令, 所以epoll不是AIO
        * 只有连read/write都不是用户态调用的, 而是系统调用(内核)并回调用户态函数时, 才叫AIO
    * sendfile + mmap 就有了一新的技术叫: kafka
      * 生产者: 网卡 -> kafka -> mmap -> 文件
      * 消费者: 网卡 -> kafka ->  文件 -> sendfile -> socket



### 简单关联一下Nginx

* 要满足多少个CPU, 启动多少个worker进程
* 一个worker就可以把数据压到CPU的一二三级缓存了
* 每个worker使用的是epoll, 同步非阻塞机制下的多路复用
* 只有Windows有AIO, Linux没有AIO



### 简单关联一下JVM

* 线程的成本
  * 首先堆是共享的, 线程栈是独立的, 默认可以是1MB, 可以调小, 表示单位内存上课创建更多的线程
  * 线程多了调度成本, CPU浪费, 消耗内核空间
  * 内存成本, 如4G内存, 3000个线程就占据了几乎所有内存(1千消耗1个G), 还不能new对象, 因为堆没有空间, 了, 现在只剩1个G左右了, 堆至少也得给2个G
  * 不论做C做Java都会尽可能控制线程的数量



### Redis的String

* key

  * 本质是个对象struct, 字节数组表示key, 还有其他属性如下:
  * type是针对value而言的, 描述的是redis的类型, 如string类型但是收到set的命令, 会被校验
  * encoding描述value具体的类型如str,int,raw等, 也用于校验命令是否能执行, 如k1=a, incr k就不成功

* value

* string/byte

  * 字符串
    * set
    * get
    * append
    * setrange
    * getrange
    * strlen
  * 数值
    * incr
    * incrby
    * 场景: 抢购, 秒杀, 详情页(购买数, 库存), 点赞, 评论数, 好友数
    * 可以规避并发下, 对数据库的事务操作, 完全有redis内存代替
    * 但是银行里多少钱, 不能用 redis
  * bitmap

* 二进制安全概念

  * ```shell
    > set k1 99999
    > strlen k1
    (integer) 5
    # 虽然知道是int类型, 但不会按某种数据类型存储,如short是2个字节, 就按一个字节一个字节存储
    
    > set k2 中
    > strlen k2
    (string) 3
    > get k2
    "\xe4\xb8\xad"
    # 因为shell客户端使用的是UTF-8字符集, 一个汉字占3个字节
    > redis-cli --raw
    > get k2
    "中"
    # 使用 --raw 来格式化编码
    ```

  * 字节流 VS 字符流

  * redis从socket中拿到的是字节流

  * 否则redis还要维护一套编码集转换, 显得没必要

  * 只需要客户端之间自己做编解码, 数据就不会被破坏, 换言之存储原汁原味的数据

* getset命令的背后

  * 完全可以由客户端来get, 然后再set, 但是有成本: 网络IO
  * 合并为一个操作, 将规避IO做到极致

* msetnx

  * 原子性操作, msetnx k1 v1 k2 v2, 此时若k1有值, 则 k1,k2都不成功

* 正反向索引

  * 如 "hel" 有正向索引: 0->h,  1->e, 2->l
  * 还有反向索引: -1->l, -2 -> e, -3 -> h

* **bitmap 面试重点**

  * setbit   key  offset  value
    * offset是二进制位的偏移量, 不是字节数组
    * 一个字节有8个二进制位
    * 00000000 00000000, 第一个字节的索引是0, 第二个字节的索引是1, 这是字节的索引不是offset
    * 二进制位也有索引, 00000000 00000000, 对应的offset分别的 01234567   89,10,11,12,13,14,15
    * setbit  k1  1  1
      * 长度是1,  一个字节
      * k1值变成了 01000000, 二进制表示是@符号, 根据ascii码
    * setbit  k1  7  1
      * 长度仍然是1, 因为还是使用的前8位, 没有开辟后面8位, 还是一个字节
      * 值变成了 01000001, 因为上面操作的结果还保留着, 没有清除k1这个键
      * 二进制表示是A, ascii 16进制41 -> 0100 0001, 前4位4, 后4位1 => 16进制的41是大写A
      * setbit  k1  9  1后, 长度为2, 因为超过1个字节8位, 值为A@
  * bitpos  key  bit  [start]  [end], 其中start,end是字节的索引, 不是位的索引
    * bitpos   k1  1  0  0 结果是1, 前8位: 01000000 <-> 0***1***234567
    * bitpos   k1  1  1  1 结果是9, 后8位: 01000000 <-> 8,***9***,10,11,12,13,14,15
  * bitcount   key  [start]  [end], 统计1出现过几次
    * bitcount  k1  0  1,  结果是3,   01000001 01000000总计3个1
  * bidop  operation  destkey  key [key...],  位的操作
    * setbit  k1  1  1,   setbit  k1  7  1,  也就是A <-> 0100 0001
    * setbit  k1  1  1,   setbit  k1  6  1,  也就是B <-> 0100 0010
    * bitop  and  k3    k1   k2,    相当于k1和k2做按位与操作
      * 得出k3  = @ <-> 0100 0000
    * bitop  or    k4    k1   k2,   相当于k1和k2做按位或操作
      * 得出 k4 = C <-> 0100 0011

* bitmap场景

  * 公司有用户系统, 统计用户的登录天数, 且窗口随机

    * 每年365/366天, 索性大方点儿, 400天, 对应400个二进制位, 400/8 = 50个字节
    * 用50个字节可以记录用户全年365天的登录状态
    * setbit  user3  1  1,   解释:  user3 在第二天登录了(第一天是0)
    * setbit  user3  7  1,   解释:  user3 在第八天登录了(第一天是0)
    * setbit  user3  364  1,   解释:  user3 在第365天登录了(第一天是0)
    * bitcount user3 0 50, 解释:  得到结果3, 一年内登录过3天
    * strlen  user03, 解释: 得出46, 只用了46个字节
    * 占空间: 46B * 10,000,000(一千万用户) = 460,000,000B = 460MB

  * 京东618做活动, 用户登录送礼物, 大库备货多少礼物, 假设京东有2E用户

    * 用户分僵尸用户, 冷热用户, 忠诚用户

    * 活跃用户统计

    * 如 1号-3号范围内, 连续登录去重

    * setbit 20190101  1  1     第一天user1登录, user1  -> 1,  登录 -> 1, 01000000

    * setbit 20190102  1  1     第二天user1登录, user1  -> 1,  登录 -> 1, 01000000

    * setbit 20190102  7  1     第三天user2登录, user2  -> 7,  登录 -> 1, 01000001

    * biop  or  destkey  20190101  20190102

    * 得出 destkey = 01000001, 此时完成了去重的操作, 因为user1这2天都登录了

    * bitcount  destkey  0  -1, 得出 2个用户在这个时间范围内登录了

      

* 字符集扩展

  * 其他字符集不再对ascii进行重编码
  * 规则是 0XXXXXXX, 第一位是0, 后面代表不同的内容
  * 若自己写程序读取字节流, 发现当前自己开头是0, 那么就代表着是ascii码
  * 若开头111认为是UTF-8, 除了这3个字节, 还要读取后面字节, 拼成数值, 与对应的码表, 获取对应的字符



---



### List类型

* 本质是双向链表
  * 可以描述栈和队列
  * 栈
    * 同方向 push 和 pop
  * 队列
    * 反方向 push 和 pop
  * 数组
    * 因为可以用索引来操作
  * 阻塞队列 (单播队列)
    * 有带阻塞的命令

* key
  * 有head和tail这2个属性
* lpush 从左边推送数据
  * lpush  k1  a  b  c  d  e  f
  * 在内存中的顺序是:  f  e  d  c  b  a, 因为是从左向右
  * lpop 得到 f
* rpush 从右边推送数据
  * rpush  k2  a  b  c  d  e  f
  * 在内存中顺序是:     a  b  c  d  e  f
  * lpop后得到 a
* lrange key start end,  查看范围内的元素
  * lrange k1 0 -1 得到 f e d c b a
* iindex key index, 根据索引获取元素
  * lindex  k1  2  得到 d (0,1,2的第2个位置)
* lset  key  index   value, 将第n个值改变
  * lset  k1  3  x  得到  f  e  d  x  b  a
* lrem  key  count  value, 删除key链表中的元素, 根据value值, 因为list不去重, 所以要指定重复次数count
  * lpush  k3   1 a 2 b 3 a 4 c 5 a 6 d
  * lrem  k3  2  a  得到 d 6 5 c 4 3 b 2 a 1, count若>0, 则从head开始计算, 若<0从tail开始计算
  * lrem  k3  -2  a  得到 d 6 a 5 c 4 3 b 2 1, count若>0, 则从head开始计算, 若<0从tail开始计算
  * 
* linsert  key  BEFORE|AFTER  piovt   value
  * linsert   k3  after  6  a, 在元素值6后面插入一个值a
  * linsert   k3  before 3  a, 在元素值3前面插入一个值a
  * 得出的结果  d 6 a 5 c 4 a 3 b 2 a 1
* blpop 阻塞弹出元素
  * client1 blpop k8 阻塞
  * client2 blpop k8 阻塞
    * client3 rpush k8 a
    * 此时client1 停止阻塞, 并返回a
    * client3 rpush k8 b
    * 此时client2 停止阻塞, 并返回b
    * 因为client1 先阻塞的





### hash类型

* hashmap套一个hashmap
* 想象如果没有这种数据结构如何实现
  * set sean::name 'sean'
  * set sean::age  18
  * 问题: 成本, 如果sean有一百个字段, 网络IO也要一百次
* hset 
* hget  key  field
* hgetall

* 也可以对field进行数值运算
* 场景
  * 点赞
  * 收藏
  * 详情页





### set类型

* 无序, 去重
* 常规操作
  * CRUD如 sadd smember srem
* 集合操作
  * sinter k1 k2 获取交集
  * sintersotre k3 k1 k2 将k1,k2的交集赋值给k3, 规避IO操作
  * sunion 合并集合并去重复
  * sdiff k1 k2  求差集, 这个是有方向的, 与 sdiff k2 k1结果不同
* 随机事件
  * srandmember key count
  * count为正数时, 取出一个**去重的结果集**, 不能超过已有集合
  * count为负数时, 取出一个**带重复的结果集**, 一定满足你要的数量
  * count为0时, 不返回
* 应用场景
  * 抽奖: 10个奖品, 
    * 用户>10 或者 <10
      * 用户多如>10, 使用spop, 随机抽一个, 并弹栈
    * 中奖  重复 vs 不重复



### sorted set类型

* 有序set, 注意不是放入的顺序, 而是根据排序规则的顺序
* 如果不给出分数值, 那么默认会按字典排序
* 物理内存左小右大, 不随命名变化而变化
* zadd k1 8 apple 2 banana 3 orange
* zrange k1 0 -1     结果  banana orange apple
* zrange k1 0 -1 withscores 结果  banana 2 orange 3 apple 8
* zrangebyscore k1 3 8     结果  orange  apple
* zrange k1 0 1   结果  banana orange
* 倒叙 zrevrange k1 0 1 结果  apple orange
* 注意与 zrange k1 -2 -1   结果  orange apple   是不一样的, 这个是正序的倒数第2和倒数第1, 不是倒数第1和倒数第2
* zrank k1 apple, 查询 元素的排名





### redis进阶使用







### 缓存常见问题, 面试题回答

* 雪崩
* 缓存穿透
  * 客户端查询缓存, key不存在, 则需要去数据库中查询, 当缓存和数据库都不存在, 则请求都打到数据库, 如果请求量很大, 会给数据库造成很大压力
  * 方法一:
    * 当数据库查询返回null时, 在缓存插入 key -> null, 当再次请求时, redis直接返回null即可
  * 方法二: 布隆过滤器
    * 请求过来时, 先去布隆过滤器校验是否存在, 不存在就返回不存在
    * 命中不一定存在, 未命中一定不存在
* 布隆过滤器原理
  * bloom是一个bit数组, 如长度为8的bit数组, 使用3个不同函数映射baidu这个key
  * 得出0, 4, 7这3个槽slot, 那么将这3个索引对应的值, 从0改成1
  * 请求qq和abc, qq -> 0, 4, 7说明命中但未必存在, abc -> 0, 1, 2.
  * 0,1,2这索引值, 虽有0的值是1, 但是1和2上的值都是0. 所以abc这个值肯定不存在
  * 这时qq穿透, abc没有穿透返回不存在, 此时要做一件事
  * 增加redis的key为abc,标记abc的值为不存在, abc->"not exist"类似这种标识, 并设置过期时间
  * 下次客户端再次查询abc时, 就返回不存在即可, 当然是在未过期的情况下
  * 若数据库增加了元素, 必须完成元素的bloom的添加
  * 这产生另一个问题: 双写
* 1. 
* 一致性
* 双写



### redis做数据库还是缓存

* 缓存数据***不那么重要***, 不是说不重要, 是和数据库相比而言
* 缓存:数据可以丢, 做数据库:数据不能丢
* 不是全量数据, 要全量直接数据库就好了, 别用缓存了
* 缓存应该随着访问变化, 也就是热数据
* redis里的数据怎么能随着业务变化, 只保留热数据, 因为内存是瓶颈, 有限+昂贵
* 业务逻辑与有效期有强关联关系, 且有随着访问变化, 冷数据应该被淘汰掉
* 过期
  1. 会随着访问延长?  不会
  2. 发生写入, 会剔除过期时间
  3. expireat  key  timestamp, 说明倒计时, 不能延长redis的key的过期时间
  4. LRU  多久没碰她
  5. LFU  碰了多少次
* 过期原理
  * 官网上有
  * 被动和主动的方式
  * 被动方式: key过期了很长时间, 不访问不会删除, 删除发生在访问节点
  * 主动方式: 每10秒做一次, 
    1. 随机的20个key做相关检测
    2. 删除所有过期的key
    3. 如果有多于25%的key过期, 在重复步骤1
* 若做数据库
  * 缓存淘汰策略是不淘汰, 当内存满时写入返回错误





### 持久化

* 问题: 做库还是做缓存
  * redis 和 mysql都做数据库使用, redis+mysql都做数据库用, 这种描述不对
  * 若redis做库用, 则mysql与redis没有强一致性, 而是从mysql异步写入redis
  * 做缓存的目的: 极速, 做数据库的要求:速度+持久性
* 存储层
  * 因为redis数据是存在内存的, 掉电易失, 需要持久化到硬盘
  * 快照(副本)    全量
  * 日志              增量
* RDB 根据时点性(或周期性)备份数据
  * 问题: 8点时备份, 并不是一瞬间就能写入磁盘, 如需要30分钟, 那么写入磁盘的数据是8:00, 还是8:30?
  * 如果要求是8:00, 则是强一致性的体现, 需要加锁阻塞, 此时redis不能对外提供服务
  * **伪命题:** 如果8:00时, a=3, b=4, 8:15备份到b, b=6了, 备份时,b的值为4还是为3? 
  * 需要引入管道的知识点
    * 衔接前一个命令的输出  作为  后一个命令的输入
    *  管道会触发创建子进程
      * echo $$ | more,  永远是打印当前ssh的进程, 因为$$的优先级高于管道|, echo先执行了, 所有永远是当前ssh的进程号
      * echo $BASHPID | more 打印的是more的进程, 因为$BATHPID的优先级比管道|低, 所以管道执行后输出, 管道输入的结果
    * 使用linux会有父子进程的概念
      * 父进程的数据, 子进程是否能看得到?  看不到
      * 常规思想, 进程是要做数据隔离的
      * 进阶思想, 父可以让子看到数据, export命令把变量A变成环境变量A, 否则子看不到父进程的变量A
      * 现在进程修改环境变量A(不export的情况下),  不会修改父进程的环境变量A
      * 同时, 父进程也修改这个变量A, 子进程里的变量A, 不会被修改, 父进程不会破坏子进程
    * 问题: 创建子进程的速度应该是什么程度
      * 问题: 如果父进程是redis, 内存10个G, 想做到非阻塞情况下还要备份数据
        * 创建子进程的成本	
          * 速度
          * 内存空间够不够
        * fork系统调用
          * 创建速度很快, 且对空间要求不是很多
          * 虚拟地址 -> 物理地址的映射, fork的过程并不是物理内存重新拷贝了一份, 而是子进程的指针也指向同一个物理内存地址, 父子进程指向的是同一块内存地址
          * copy on write概念: 写时复制, 父进程创建子进程时, 不会复制物理内存里的值, 但是写入一个值的时候, 会把原值复制给子进程
            * 优点: 创建进程变快了, 且根据经验, 父进程不可能把所有变量都改一遍 从而触发 copy on write
      * 理论上是一个副本
    * 所以: 因为是子进程来备份数据, 且主进程改变量值是基于copy on write, 主进程改变的值会引用新的内存地址, 子进程引用的还是原来的地址, 所以值不会改变, 时点是正确的, 如上面提到的8:00
* RDB触发方式, redis database file的意思
  * save命令, 手动触发, 前台会阻塞, 场景:明确要关机, 手工维护备份数据
  * bsave命令, 手动触发, 后台执行不会阻塞
  * 配置文件给出bsave规则, 用的是save这个标识
  * 弊端
    * 不支持拉链, 永远只有一个dump.rdb文件
    * 需要运维定制策略, 做时间戳与dump文件的关系, 这样才能有时光机的概念
    * 丢失数据相对多一些, 时点与时点之间的窗口容易丢失
  * 优点
    * 类似java的序列化, 把内存数据序列化到磁盘, 恢复的速度相对AOF快
* AOF  append only file的意思
  * 将redis的写操作记录到文件中
  * 丢失数据相对少
  * RDB和AOF可以同时开启, 如果开启了AOF, 只会用AOF恢复
  * 4.0以后, AOF是包含RDB一个全量, 追加增量, 记录新的写操作
  * 问题: redis运行了10年, 开启了AOF, 第10年时, redis挂了
    * AOF多大: 很大10T比如,  恢复的时候会不会溢出?
      * AOF是操作的日志, 只要当时操作的时候redis内存没有溢出, 那么再从头执行一次, 也不会溢出
      * 前提是线性执行这个文件
    * 恢复要多久: 需要5年可能
  * 弊端
    * 体量大, 无限变大
    * 恢复慢
  * 设计一个方案让AOF足够小, 再不丢失数据的情况下
  * 让日志只记录增量, 有一个合并的过程, 类似 hdfs的 fsimage + edits.log
  * 4.0前
    * 重写: 删除抵消 和 合并命令, 最终也是一个纯指令的日志文件
  * 4.1后
    * 重写: 将老的数据RDB到aof文件中, 将增量以指令的方式append到AOF
    * AOF成为混合体, 利用RDB的快, 利用了日志的全量, 2个优点
    * ***触发重写*** 才会将RDB和AOF组成混合体
* 原点
  * redis是内存数据库, 写操作会触发IO操作, 拖慢redis处理快的特性, 所以有3个级别可调
  * no, always, 每秒
  * 内核知识点: 为什么java写文件最后要调用flush方法?
    * 因为操作的是内核中的buffer, 不是直接操作磁盘, 
    * 当buffer满了, 或者确定要向磁盘写入的时候, 调用flush来让内核操作buffer写入磁盘, 最后java在关闭流
  * no的概念不是不写, 而是写入buffer, 但是不调用flush, 等buffer满了以后, 内核自己调用flush写入磁盘
  * 弊端是可能丢失一个buffer大小的数据





### 多机

* 单机问题
  1. 单点故障
  2. 容量有限
  3. 压力, 包括计算, 带宽
* AKF概念, 微服务拆分原则第一项
  * x,y,z三个轴
    * X轴:  全量镜像
    * Y轴:  按照功能/业务   划分成不同的实例存储, 每个集群不是一类数据
    * Z轴:  数据分片,  优先级逻辑再拆分
  * x轴做redis实例的副本, 主备模式,  主备不等于主从
  * x轴扩展, 能解决单点故障的问题, 能解决容量有限的问题吗? 不能: 因为主备的数据都是全量的
* 一致性概念
  * redis 1主2从, node1提供写, node2和3提供查查询
  * 强一致性,  node1写时会阻塞, 因为node1,2,3之间同步数据, 导致node1不可用
  * 最终一致性: 若, node1与2,3之间异步写, 则1,2,3都有可能出问题, 导致数据丢失
  * 此时在node1和23之间增加类kafka的概念, 可以提高概率保证数据不丢
* 主从VS主备
  * 主备: 客户端只能访问主, 不能访问备机, 备机是不参与业务的
  * 主从: 客户端可以访问主,也可以访问从, 主从涉及到复制的概念
  * 大部分企业中用的还是主从, 问题是: 主自己形成一个单点
  * 所以需要对主做HA, 一般HA是对主做, 基本不对从做
* 如何做HA
  * 人监控不可靠, 且成本高
  * 程序监控, 但是一个程序监控, 就***又变成单点问题***了
  * 那么监控程序, 也必须是多点, 一变多问题
  * 那么假设3个监控程序分不同节点, 监控同一个redis, 3个都给出redis挂了, 则出现了强一致性. 但是如果其中一台延迟了, 不能给出结果, 如通信失败. 说明强一致性会破坏可用性, 监控就不可用了, 阻塞住了
  * 一部分给出redis挂了的结果, 那么问题是一部分几个?
    * 推导:  ***1个说***, 还是 ***2个说***redis挂了 才算数
    * 1个说挂了, 没法确定是否是自身原因, 如自己挂了, 或者网络不通了. 所以1个说是统计不准确的
    * 而且产生网络分区的问题, 相当于从外部看监控结果, 有2个不同的版本, 脑裂了
    * 由此引出了 分区容错性, 系统对网络分区能容忍, 从而不需要全量的一致
      * 如Eureka, eureka也是集群部署, 有系统看到服务10台可用, 其他系统看到统一服务20台可用, 这个不要紧, 不影响使用, 因为只需要1台且能通信就可以了
    * 2个说挂了
      * 另一个说什么都不算数
      * 因为2个***势力范围***  大于 另一个的势力范围
      * 现在是 2/3, 如果变成 2/4, 会怎样?
      * 变成脑裂, 其中2个说挂了, 另外2个说没挂, 都满足半数, 那听谁的? 票数都一样没法决策了, 除非3/4, 才能决策
      * 2/3 能决策, 3/4能决策, 3/5也能决策
      * 所以得出  x = n/2 + 1 能决策, 过半
      * 一般使用奇数台, 为什么?
      * 这样描述: 2/3, 三台里两台过半能决策, 反过来说, 三台里允许一台出问题
      * 3/4的话, 四台里三台过半能决策, 也就是只能允许一台出问题
      * 三台集群与四台集群能承担的风险是一致的, 但是成本四台集群高, 因为还多了一台, 而且四台比三台更容易出现某一台的问题/故障



### 多机数据划分问题

* 单点的就不再讨论了

* hash + 取模, 弊端: 扩展难, 每次求余会到确定的一台机器上, 受限于模数(除数)
* random随机, 弊端: 放入简单, 没法获取, 客户端不知道数据生产者放到哪里去了
* 一致性Hash, 哈希, crc, fnv等算法, 映射算法, 没有取模的过程
  * 要求key和node都参与hash计算
  * 规划一个环形环
  * 优点: 加节点不会造成全局洗牌
  * 缺点: 造成一小部分数据不能命中	
    * 问题: 加节点或删节点时击穿, 流量压到mysql
    * 方案: 设法去取离我们最近的2个物理节点
    * 这种方案更倾向于缓存
  * 增加虚拟节点, 一个物理设备的IP拼上数字算hash, 分布在环上, 指向这个物理节点
  * 可以解决数据倾斜的问题
* 问题: 多个客户端连接多个redis, 对客户端,对redis都是负担
  * 中间引入代理服务器, hold住请求socket, 并实现反向代理和负载均衡策略
  * 如**[twemproxy](https://github.com/twitter/twemproxy)**
* 问题: 这3个模式都不能做数据库使用(cluster)
  * 预分区概念
* redis的cluster模型
  * 是一种无主模型
  * client连接那个都无所谓
  * client连接A机器, 要获取k1的值, A机器没有, 但是A机器有一致性hash算法和mapping规则, 所以知道k1在那个机器上, 在B机器上,此时返回给client, 让client重定向到B机器查询k1的数据





### 进群的问题

* 概念:  击穿, 穿透,雪崩可以不是一个概念

* 击穿
  * 少量的key, 且高并发到达了, 导致大量流量涌入DB, 且获取是相同的数据
  * redis作为缓存, 必然存在2个概念: 1过期时间, 2开启淘汰策略
  * 客户端访问数据, 这些数据刚好过期/淘汰, 此时需要去数据库获取数据
  * key的过期造成并发访问数据库, 前提是肯定发生了高并发
  * 解决方法:
    1. 第一个线程请求redis发现key没有值, 并尝试抢占锁
    2. 第一个线程此时设置分布式锁, setNX(key), 而第N个线程此时会执行第一步, 获取不到锁
    3. 第一个能获取到锁的线程, 去访问数据库, 并将数据同步至缓存内, 然后释放锁(时间片段II)
    4. 第N个获取锁失败的, 随机等待一会儿sleep(time随机)(时间片段I)
    5. 第N个结束sleep后, 重新开始第一步
  * 这种解决办法的问题
    * 问题1 死锁问题, 如果第一个线程挂了, 锁一直没有释放
      * 解决: 过期时间
    * 问题2 在锁拥有过期时间后, 锁没有挂, 但是超时了(到了过期时间了)
      * 解决: 多线程, 对去DB取数据的线程, 增加一个线程, 用于查看redis的key是否被刷新, 也就是取DB的线程是否完成, 若没有完成, 增加锁的失效时间
      * 一个线程去DB取, 另一个线程监控是否取回来, 决定是否延长锁失效时间
* 穿透
  * 接收的查询是根本不存在的数据, 缓存和DB都没有的数据
  * 解决方案:
    * bloom过滤器
      * 法一: 客户端可植入bloom过滤器的算法并维护数据, 可以直接减少redis的压力, 但是对客户端的内存压力比较大
      * 法二: 客户端只包含算法, bitmap维护在redis, 这样服务是无状态的
      * 法三: redis服务集成bloom模块, 客户端是瘦的, 
      * 缺点: 只能增加不能删除, 有些数据删改的话
      * 所以需要换一个过滤器: 布谷鸟, bloom+
    * 放置空值的key,   设置key的值为null(约定好一个空key的值, 不是redis自己的nil)
* 雪崩
  * 很像击穿, 但是比击穿更容易发生
  * 大量的key同时失效
  * 分不同场景
    1. 到时点必须过期/换血,  如0点分割今天的利率和第二天的利率
    2. 对时点无关
       - 解决: 合理设置随机过期时间的expire值, 让分布更加均匀
  * 如果是到时间点必须过期
    * 解决: 使用上面击穿的方式, 通过分布式锁指定一个线程同步数据
    * 并且让客户端在0点延迟N秒钟或N毫秒
* 分布式锁
  * setNX
  * 过期时间
  * 守护线程, 事务线程, 延长过期
* 





阿萨德

