# Redis

### 常识

* 磁盘的维度
  1. 寻址的速度: ms毫秒级别的
  2. 带宽: 单位时间有多少个字节流动, GB/MB 级别
* 内存
  * 寻址的速度: ns 纳秒 (秒>毫秒>微秒>纳秒)
    * 硬盘在寻址上比内存慢了10万倍
  * 带宽: 很大
* I/O buffer 成本问题
  * 磁盘有磁道和扇区
    * 一扇区 512Byte字节
    * 如果一个区域足够小, 带来的问题是成本变大->索引
    * 格式化磁盘时有4K对齐, 真正使用硬件时并不是512B为读写量
    * 操作系统, 无论读取多少都是最少4K, 从磁盘上拿
  * 随着文件变大, 读取速度变慢
    * 硬盘成为瓶颈, 也就是I/O成为瓶颈
* 数据库的出现
  * data page 概念
    * 大小为4K,  与操作系统一次IO相同, 放一行一行的数据, 
    * 相当于数据块, 并由软件统一管理, 使得其变得更线性, 而不是散落在磁盘各处
      * 如果数据库定义小了, 则亏得慌, 如定义1k, 但每次IO是4K, 有3k没有发挥作用
      * 可以往大了调整
      * 个人理解: Hadoop的数据块概念就可以很大
  * 索引
    * 也是基于4K的数据块
    * 记录并指向data page的地址
    * 存储于硬盘
  * 关系型数据建表: 必须给出schema
    * 类型: 字节宽度
    * 存储: 倾向于行级别的存储, 即使一行除了主键其他字段无数据, 也会给这些字段开辟空间
      * 站位的好处: 为将来增删改提供扩展性, 降低成本
  * 使用索引需要内存中准备一个B+ Tree
    * 所有叶子节点为硬盘上的索引
    * 树干(非叶子节点) 存储于内存之中
  * 命中缓存的流程
    * where条件命中内存中的B+树的节点
    * 也就是命中磁盘中索引块
    * 数据库加载磁盘索引块到内存, 解析得出数据块地址
    * 通过数据块地址将数据块内容加载到内存, 并返回给用户
    * 最终目的减少IO的次数
  * 问题: 如果数据库的表数据量很大, 性能下降, 查询效率会变低
    * 如果表有索引, 增删改变慢
      * 原因, 修改完数据, 还会修改索引, 会调整索引的位置
    * 查询速度
      1. 数据量很大前提下(假设达到物理极限), 1个或者少量查询, 且命中索引的情况下, 依然很快
      2. 并发或复杂SQL到达, 要获取多个data page, 会受硬盘带宽影响速度
  * 数据在磁盘和内存体积不一样, 因为磁盘中没有对象概念, 引用需要冗余数据
    * 将2T磁盘数据, 转换成内存的数据结构, 要<2T
    * 但是基于内存的关系型数据库很贵, 贵到买不起
* 问题: 数据库数据增长很大很快, 又没有基于内存的关系型数据库, 如何操作?
  * 折中方案: 缓存, 如memcached, redis
* 2个基础设置
  1. 冯诺依曼体系的硬件
  2. 以太网, TCP/IP网络(潜台词: 不稳定)

* **技术选型**&**技术对比**能力

  * [数据库引擎网](https://db-engines.com/en/)    包括了关系型,内存kv型,文档型等等
  * 基于此网站来做数据库的选型

* memcached VS redis

  * 第一反应, memcached即使没有复杂数据类型, 也可以用json表示
    * 世界上有3种数据表示:
      * k = a
      * k = [1,2,3]
      * k = { x = y },  k = [{}, {}]

  * 数据结构
    * memcached: 他的value没有类型的概念
    * redis: 他的value有类型概念, 如string, list等等
    * 这不是重点, 因为可以用json代替
    * 但是, 如果client要从缓存中读取value中的一个元素, 成本就不一样了
      * memcached: 返回所有value到client, 涉及到server,网卡,IO,解码json
      * redis: 类型不是很重要, 重要的是redis的server对每种类型都有自己的方法
      * 这样就规避的了上面的问题, 使用**命令**来代替**编码的实现**, 也实现了解耦
      * **计算向数据移动**

### 源码安装redis

* 安装过程
  1. yum install wget
  2. cd ~  &&  mkdir soft  &&   cd soft
  3. wget redis的下载地址
  4. tar xf redisXX.tar.gz # 这里没有v也是为了规避IO
  5. cd redis-src
  6. 看README.md
  7. make
  8. yum install gcc
  9. make distclean # 因为之间make过, 所以再次make时删除之前make过的内容
  10. make
  11. cd src # 查看, 此时生成了可执行程序
  12. cd.. #出来
  13. make install PREFIX=/opt/mashibing/redis
  14. vi /etc/profile
  15. export REDIS_HOME=/opt/mashibing/redis5
  16. export PATH=$PATH:$REDIS_HOME/bin
  17. source /etc/profile
  18. cd utils
  19. ./install_server.sh # 可执行一次或多次

* 知识点

  * 一个Linux操作系统(不论是物理机还是虚拟机) 可以有多个redis实例(进程), 通过端口号区分
  * 可执行程序只有一份, 但是内存中未来的多个实例, 需要各自的配置文件和持久化目录等资源
  * service redis_6379 start|stop|status  >  linux  /etc/init.d/redis_6379这个脚本

  

### redis特性

* 单进程, 单线程, 单实例, 一秒能hold住很多并发的请求, 那么他是如何变得很快的?
  * 客户端连接, 先到达内核, tcp握手
  * redis和内核之间使用的是 epoll, 非阻塞多路复用技术, 也是内核提供的一种系统调用
  * redis可以通过epoll系统调用, 来遍历不同客户端连接, 谁有数据就处理谁
  * 且可以满足
* epoll
  * BIO时期
    * 当内核下客户端client连接过来, fd 8, fd 9
    * 操作系统提供一种读操作, read命令,  现在有线程/进程read fd8, 和另一线程/进程read fd9
    * 此时socket在这个时期是阻塞的, 也就是read命令阻塞不能返回, 等待client 对fd 8做写入操作
    * 如果现在, fd 9有数据写入, CPU时间片上只能有一个线程处理, 此时还轮不到fd 9处理
    * 这样会导致, 当client增多时, 需要抛出更多的线程, client没有写入数据的时候, 很多线程会阻塞
    * CPU并没有处理真正到达的数据, 资源浪费, 且切换线程是有成本的
  * NIO时期(同步非阻塞时期), 为了提高硬件利用率, 内核发生变化
    * socket fd可以是 nonblock, 通过查询 man read 得出, read 命令有 nonblock选项
    * 此时不阻塞了, CPU可以只跑一个进程, 这个线程里写一个死循环
    * 调用完 read f 8, 就调用read fd 9
    * 如果fd8没有数据, fd9有数据, 跳过fd8, 处理fd9
    * 这个轮询发生在用户空间
    * 同步非阻塞提现在, 调用read方法后可以继续往下走不阻塞, 读fd的数据还是这个唯一的线程来做, 这叫同步
    * 问题: 如果有1000个fd, 代表**用户进程**轮询调用1000次**内核**, 成本很大
      * 也就是用户态和内核态切换, CPU保护现场恢复现场等资源消耗, 成本消耗
      * 想减少系统调用, 用户自己无法实现, 需要内核向前发展
  * 







阿萨德

