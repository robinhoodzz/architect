# Redis

### 常识

* 磁盘的维度
  1. 寻址的速度: ms毫秒级别的
  2. 带宽: 单位时间有多少个字节流动, GB/MB 级别
* 内存
  * 寻址的速度: ns 纳秒 (秒>毫秒>微秒>纳秒)
    * 硬盘在寻址上比内存慢了10万倍
  * 带宽: 很大
* I/O buffer 成本问题
  * 磁盘有磁道和扇区
    * 一扇区 512Byte字节
    * 如果一个区域足够小, 带来的问题是成本变大->索引
    * 格式化磁盘时有4K对齐, 真正使用硬件时并不是512B为读写量
    * 操作系统, 无论读取多少都是最少4K, 从磁盘上拿
  * 随着文件变大, 读取速度变慢
    * 硬盘成为瓶颈, 也就是I/O成为瓶颈
* 数据库的出现
  * data page 概念
    * 大小为4K,  与操作系统一次IO相同, 放一行一行的数据, 
    * 相当于数据块, 并由软件统一管理, 使得其变得更线性, 而不是散落在磁盘各处
      * 如果数据库定义小了, 则亏得慌, 如定义1k, 但每次IO是4K, 有3k没有发挥作用
      * 可以往大了调整
      * 个人理解: Hadoop的数据块概念就可以很大
  * 索引
    * 也是基于4K的数据块
    * 记录并指向data page的地址
    * 存储于硬盘
  * 关系型数据建表: 必须给出schema
    * 类型: 字节宽度
    * 存储: 倾向于行级别的存储, 即使一行除了主键其他字段无数据, 也会给这些字段开辟空间
      * 站位的好处: 为将来增删改提供扩展性, 降低成本
  * 使用索引需要内存中准备一个B+ Tree
    * 所有叶子节点为硬盘上的索引
    * 树干(非叶子节点) 存储于内存之中
  * 命中缓存的流程
    * where条件命中内存中的B+树的节点
    * 也就是命中磁盘中索引块
    * 数据库加载磁盘索引块到内存, 解析得出数据块地址
    * 通过数据块地址将数据块内容加载到内存, 并返回给用户
    * 最终目的减少IO的次数
  * 问题: 如果数据库的表数据量很大, 性能下降, 查询效率会变低
    * 如果表有索引, 增删改变慢
      * 原因, 修改完数据, 还会修改索引, 会调整索引的位置
    * 查询速度
      1. 数据量很大前提下(假设达到物理极限), 1个或者少量查询, 且命中索引的情况下, 依然很快
      2. 并发或复杂SQL到达, 要获取多个data page, 会受硬盘带宽影响速度
    * 解决方案
      1. 使用昂贵的基于内存的关系型数据库
      2. 使用缓存做为中间件
  * 数据在磁盘和内存体积不一样, 因为磁盘中没有对象概念, 引用需要冗余数据
    * 将2T磁盘数据, 转换成内存的数据结构, 要<2T
    * 但是基于内存的关系型数据库很贵, 贵到买不起
* 问题: 数据库数据增长很大很快, 又不可能使用基于内存的关系型数据库, 如何操作?
  * 折中方案: 缓存, 如memcached, redis
* 2个基础设施
  1. 冯诺依曼体系的硬件
  2. 以太网, TCP/IP网络(潜台词: 不稳定)

* **技术选型**&**技术对比**能力
  * [数据库引擎网](https://db-engines.com/en/)    包括了关系型,内存kv型,文档型等等
  * 基于此网站来做数据库的选型

* memcached VS redis

  * 第一反应, memcached即使没有复杂数据类型, 也可以用json表示
    * 世界上有3种数据表示:
      * k = a
      * k = [1,2,3]
      * k = { x = y },  k = [{}, {}]

  * 数据结构
    * memcached: 他的value没有类型的概念
    * redis: 他的value有类型概念, 如string, list等等
    * 这不是重点, 因为可以用json代替
    * 但是, 如果client要从缓存中读取value中的一个元素, 成本就不一样了
      * memcached: 返回所有value到client, 涉及到server,网卡,IO,解码json
      * redis: 类型不是很重要, 重要的是redis的server对每种类型都有自己的方法
      * 这样就规避的了上面的问题, 使用**命令**来代替**编码的实现**, 也实现了解耦
      * **计算向数据移动**

### 源码安装redis

* 安装过程
  1. yum install wget
  2. cd ~  &&  mkdir soft  &&   cd soft
  3. wget redis的下载地址
  4. tar xf redisXX.tar.gz # 这里没有v也是为了规避IO
  5. cd redis-src
  6. 看README.md
  7. make
  8. yum install gcc
  9. make distclean # 因为之间make过, 所以再次make时删除之前make过的内容
  10. make
  11. cd src # 查看, 此时生成了可执行程序
  12. cd.. #出来
  13. make install PREFIX=/opt/mashibing/redis
  14. vi /etc/profile
  15. export REDIS_HOME=/opt/mashibing/redis5
  16. export PATH=$PATH:$REDIS_HOME/bin
  17. source /etc/profile
  18. cd utils
  19. ./install_server.sh # 可执行一次或多次

* 知识点

  * 一个Linux操作系统(不论是物理机还是虚拟机) 可以有多个redis实例(进程), 通过端口号区分
  * 可执行程序只有一份, 但是内存中未来的多个实例, 需要各自的配置文件和持久化目录等资源
  * service redis_6379 start|stop|status  >  linux  /etc/init.d/redis_6379这个脚本

  

### redis特性

* 单进程, 单线程, 单实例, 一秒能hold住很多并发的请求, 那么他是如何变得很快的?
  * 不严谨, 只是针对处理客户端请求时, 是单进程单线程单实例, 后台有备份的线程, 这个是不与客户端交互的
  * 客户端连接, 先到达内核, tcp握手
  * redis和内核之间使用的是 epoll, 非阻塞多路复用技术, 也是内核提供的一种系统调用
  * redis可以通过epoll系统调用, 来遍历不同客户端连接, 谁有数据就处理谁
  * 因为单进程, 所有数据到达并被redis处理是"有顺序的", 后面的共享空间的链表
    * 顺序性特指: 每个连接内的命令的顺序处理的
    * 若, 2个socket对K1进行操作, 很难判定谁先后, epoll先轮到谁了说不准, 所以没法判定顺序, 也就socket1和socket2是都有可能先执行
* epoll
  * BIO时期
    * 当内核下客户端client连接过来, fd 8, fd 9
    * 操作系统提供一种读操作, read命令,  现在有线程/进程read fd8, 和另一线程/进程read fd9
    * 此时socket在这个时期是阻塞的, 也就是read命令阻塞不能返回, 等待client 对fd 8做写入操作
    * 如果现在, fd 9有数据写入, CPU时间片上只能有一个线程处理, 如正在处理fd8的read, 此时间片内还轮不到fd 9处理
    * 这样会导致, 当client增多时, 需要抛出更多的线程, client没有写入数据的时候, 很多线程会阻塞
    * CPU并没有处理真正到达的数据, 资源浪费, 且切换线程是有成本的
  * NIO时期(同步非阻塞时期), 为了提高硬件利用率, 内核发生变化
    * socket fd可以是 nonblock, 通过查询 man read 得出, read 命令有 nonblock选项
    * 此时不阻塞了, CPU可以只跑一个进程, 这个线程里写一个死循环
    * 调用完 read fd 8, 就调用read fd 9
    * 如果fd8没有数据, fd9有数据, 跳过fd8, 处理fd9
    * 这个轮询发生在用户空间(用户态)
    * 同步非阻塞体现在, 调用read方法后可以继续往下走不阻塞, 读fd的数据还是这个唯一的线程来做, 这叫同步
    * 问题: 如果有1000个fd, 代表**用户进程**轮询调用1000次**内核**, 成本很大
      * 也就是用户态和内核态切换, CPU保护现场恢复现场等资源消耗, 成本消耗
      * 想减少系统调用, 用户自己无法实现, 需要内核向前发展
  * select 多路复用的NIO
    * 把用户态的轮询放到了内核里, 内核里多了一个系统调用: select
    * 用户态调用select传入1000个fd, 内核监控这些fd, 内核等待直到有一个或多个I/O操作处于ready状态后返回, 参考: man select
    * 用户态再拿着返回的文件描述符, 再去调用read命令
    * 相当于还是调用wait , 但是不会调用没有ready, 没有数据写入的fd
    * 与上一个时期相比, 系统调用更精准了
    * 还是有问题: 每次要传入很多个fd进去, 返回后再去调用read, 是否还能再优化?
      * 抽象成: 用户态和内核态来回拷贝数据, 能否零拷贝
      * 决策环节时, 文件描述符fd成为累赘了
  * epoll 伪AIO
    * mmap命令, map or unmap files or devices into memory
    * 内核有内核的内存地址空间, 应用进程有应用进程内存地址空间, 都是虚拟地址空间, 物理内存上就是2个不同的区域而已, 内核的区域进程是不能直接访问的, 要通过API传参访问, 也就是拷贝来拷贝去
    * 索性弄出一个内核态和用户态都可以访问的空间, 称之为共享空间
    * 共享空间是通过内核的mmap系统调用实现的
    * 有了共享空间, 用户态就不用在自己的空间里写fd了, 要不然还得再拷贝一次到共享空间
    * 空箱空间是用户态内存空间的一部分, 也是内核态内存空间的一部分, 各自无需再单独维护fd
    * 空间中存放了 红黑树和链表 数据结构
      * 进程里(用户态)每多了一个fd, 就放到共享空间里的红黑树
      * 内核获取fd, 通过所有的IO/中断, 把数据达到的(ready)放到链表里
      * 当链表里有数据了, 用户态通过读取链表读取到fd, 再调用read读取数据
    * 零拷贝, sendfile
      * 现在有内核, 网卡, 文件, 应用程序
      * 文件fd3 -> 内核buffer -> read(fd3) -> 应用程序 -> write(fd4) -> 内核buffer -> 网卡请求
      * 有了sendfile之后
      * 文件fd3 -> 内核buffer -> read(fd3) -> 应用程序 -> sendfile(fd4) -> 网卡请求
    * epoll是一个大的概念, 其中有3个系统调用
      * epoll_create
        * 调用create后, 返回epoll的fd, epoll_fd
        * 未来有一个连接进来了, 就写给epoll_fd, epoll会使用共享空间mmap, 连接注册到共享空间内的红黑树, 增删改的操纵是内核完成的, 查询是用户态和内核态都可以操作的
      * epoll_ctl
        * 用户态会调用 ctl add/del sfd(socket的fd) 和 wait命令
        * 事件驱动, 内核完成那个连接fd为ready, 并写到链表里去, 维护数据是可写还是可读
        * 维护完成后, wait解除阻塞, 可以获取链表中的数据, 因为是共享空间, 所以到用户态没有数据拷贝
        * 但是此时还要单独调用 read/write命令, 所以epoll不是AIO
        * 只有连read/write都不是用户态调用的, 而是系统调用(内核)并回调用户态函数时, 才叫AIO
    * sendfile + mmap 就有了一新的技术叫: kafka
      * 生产者: 网卡 -> kafka -> mmap -> 文件
      * 消费者: 网卡 -> kafka ->  文件 -> sendfile -> socket



### 简单关联一下Nginx

* 要满足多少个CPU, 启动多少个worker进程
* 一个worker就可以把数据压到CPU的一二三级缓存了
* 每个worker使用的是epoll, 同步非阻塞机制下的多路复用
* 只有Windows有AIO, Linux没有AIO



### 简单关联一下JVM

* 线程的成本
  * 首先堆是共享的, 线程栈是独立的, 默认可以是1MB, 可以调小, 表示单位内存上课创建更多的线程
  * 线程多了调度成本, CPU浪费, 消耗内核空间
  * 内存成本, 如4G内存, 3000个线程就占据了几乎所有内存(1千消耗1个G), 还不能new对象, 因为堆没有空间, 了, 现在只剩1个G左右了, 堆至少也得给2个G
  * 不论做C做Java都会尽可能控制线程的数量



### Redis的String

* key

  * 本质是个对象struct
  * type是针对value而言的, 描述的是redis的类型, 如string类型但是收到set的命令, 会被校验
  * encoding描述value具体的类型如str,int,raw等, 也用于校验命令是否能执行, 如k1=a, incr k就不成功

* value

* string/byte

  * 字符串
    * set
    * get
    * append
    * setrange
    * getrange
    * strlen
  * 数值
    * incr
    * incrby
    * 场景: 抢购, 秒杀, 详情页(购买数, 库存), 点赞, 评论数, 好友数
    * 可以规避并发下, 对数据库的事务操作, 完全有redis内存代替
    * 但是银行里多少钱, 不能用 redis
  * bitmap

* 二进制安全概念

  * ```shell
    > set k1 99999
    > strlen k1
    (integer) 5
    # 虽然知道是int类型, 但不会按某种数据类型存储,如short是2个字节, 就按一个字节一个字节存储
    
    > set k2 中
    > strlen k2
    (string) 3
    > get k2
    "\xe4\xb8\xad"
    # 因为shell客户端使用的是UTF-8字符集, 一个汉字占3个字节
    > redis-cli --raw
    > get k2
    "中"
    # 使用 --raw 来格式化编码
    ```

  * 字节流 VS 字符流

  * redis从socket中拿到的是字节流

  * 否则redis还要维护一套编码集转换, 显得没必要

  * 只需要客户端之间自己做编解码, 数据就不会被破坏, 换言之存储原汁原味的数据

* getset命令的背后

  * 完全可以由客户端来get, 然后再set, 但是有成本: 网络IO
  * 合并为一个操作, 将规避IO做到极致

* msetnx

  * 原子性操作, msetnx k1 v1 k2 v2, 此时若k1有值, 则 k1,k2都不成功

* 正反向索引

  * 如 "hel" 有正向索引: 0->h,  1->e, 2->l
  * 还有反向索引: -1->l, -2 -> e, -3 -> h

* **bitmap 面试重点**

  * setbit   key  offset  value
    * offset是二进制位的偏移量, 不是字节数组
    * 一个字节有8个二进制位
    * 00000000 00000000, 第一个字节的索引是0, 第二个字节的索引是1, 这是字节的索引不是offset
    * 二进制位也有索引, 00000000 00000000, 对应的offset分别的 01234567   89,10,11,12,13,14,15
    * setbit  k1  1  1
      * 长度是1,  一个字节
      * k1值变成了 01000000, 二进制表示是@符号, 根据ascii码
    * setbit  k1  7  1
      * 长度仍然是1, 因为还是使用的前8位, 没有开辟后面8位, 还是一个字节
      * 值变成了 01000001, 因为上面操作的结果还保留着, 没有清除k1这个键
      * 二进制表示是A, ascii 16进制41 -> 0100 0001, 前4位4, 后4位1 => 16进制的41是大写A
      * setbit  k1  9  1后, 长度为2, 因为超过1个字节8位, 值为A@
  * bitpos  key  bit  [start]  [end], 其中start,end是字节的索引, 不是位的索引
    * bitpos   k1  1  0  0 结果是1, 前8位: 01000000 <-> 0***1***234567
    * bitpos   k1  1  1  1 结果是9, 后8位: 01000000 <-> 8,***9***,10,11,12,13,14,15
  * bitcount   key  [start]  [end], 统计1出现过几次
    * bitcount  k1  0  1,  结果是3,   01000001 01000000总计3个1
  * bidop  operation  destkey  key [key...],  位的操作
    * setbit  k1  1  1,   setbit  k1  7  1,  也就是A <-> 0100 0001
    * setbit  k1  1  1,   setbit  k1  6  1,  也就是B <-> 0100 0010
    * bitop  and  k3    k1   k2,    相当于k1和k2做按位与操作
      * 得出k3  = @ <-> 0100 0000
    * bitop  or    k4    k1   k2,   相当于k1和k2做按位或操作
      * 得出 k4 = C <-> 0100 0011

* bitmap场景

  * 公司有用户系统, 统计用户的登录天数, 且窗口随机

    * 每年365/366天, 索性大方点儿, 400天, 对应400个二进制位, 400/8 = 50个字节
    * 用50个字节可以记录用户全年365天的登录状态
    * setbit  user3  1  1,   解释:  user3 在第二天登录了(第一天是0)
    * setbit  user3  7  1,   解释:  user3 在第八天登录了(第一天是0)
    * setbit  user3  364  1,   解释:  user3 在第365天登录了(第一天是0)
    * bitcount user3 0 50, 解释:  得到结果3, 一年内登录过3天
    * strlen  user03, 解释: 得出46, 只用了46个字节
    * 占空间: 46B * 10,000,000(一千万用户) = 460,000,000B = 460MB

  * 京东618做活动, 用户登录送礼物, 大库备货多少礼物, 假设京东有2E用户

    * 用户分僵尸用户, 冷热用户, 忠诚用户

    * 活跃用户统计

    * 如 1号-3号范围内, 连续登录去重

    * setbit 20190101  1  1     第一天user1登录, user1  -> 1,  登录 -> 1, 01000000

    * setbit 20190102  1  1     第二天user1登录, user1  -> 1,  登录 -> 1, 01000000

    * setbit 20190102  7  1     第三天user2登录, user2  -> 7,  登录 -> 1, 01000001

    * biop  or  destkey  20190101  20190102

    * 得出 destkey = 01000001, 此时完成了去重的操作, 因为user1这2天都登录了

    * bitcount  destkey  0  -1, 得出 2个用户在这个时间范围内登录了

      

* 字符集扩展

  * 其他字符集不再对ascii进行重编码
  * 规则是 0XXXXXXX, 第一位是0, 后面代表不同的内容
  * 若自己写程序读取字节流, 发现当前自己开头是0, 那么就代表着是ascii码
  * 若开头111认为是UTF-8, 除了这3个字节, 还要读取后面字节, 拼成数值, 与对应的码表, 获取对应的字符





阿萨德

